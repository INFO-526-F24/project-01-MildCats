[
  {
    "objectID": "proposal.html",
    "href": "proposal.html",
    "title": "Analyzing English Premier League Match Data",
    "section": "",
    "text": "if (!require(\"pacman\")) \n  install.packages(\"pacman\")\n\n# use this line for installing/loading\npacman::p_load(here,\n               tidyverse,\n               dplyr,\n               readr)"
  },
  {
    "objectID": "proposal.html#introduction",
    "href": "proposal.html#introduction",
    "title": "Analyzing English Premier League Match Data",
    "section": "Introduction",
    "text": "Introduction\nThe English Premier League is consistently ranked as the most viewed sports league in the world. With widespread popularity and fanfare, the Premier League is an interesting subject to further explore using data methods, to uncover interesting patterns and phenomenon that fans may otherwise miss.\nMany fans also bet heavily on the outcome of matches, with the Premier League being one of the most attractive events for bettors. Thus, analyzing match data in sync with betting odds data, we may also find some interesting results that may be of relevance to fans who are risking money.\nAfter conducting data analysis, we aim to visualize and present it in an intriguing, yet easy to understand fashion, in order to make it accessible to a wide range of audience."
  },
  {
    "objectID": "proposal.html#datasets",
    "href": "proposal.html#datasets",
    "title": "Analyzing English Premier League Match Data",
    "section": "Datasets",
    "text": "Datasets\n\nMatch Data\nThe core data-set for our project is the the Premier League Match Data for the 2021-22 season. This data-set will be extended to cover matches from years 2022-2023.\nAs sports fans, we often find ourselves absorbed by the adrenaline and pace of the game, but taking a broader, objective approach can help us answer “difficult” questions like -\n\nWhy did my team lose this game (that we were sure we would win)\nIs there such a thing as home ground advantage? Do some teams objectively and quantifiably perform better on home grounds, or are there teams which are agnostic to this?\n\nHence, this data-set stood out in it’s ability to be an interesting case-study towards building an engaging project, making it our choice for this project.\n\nData Description\n\n\n\n\n\n\n\n\n\nColumn Name\nDescription\nType\nUsage in Project\n\n\n\n\nDate\nDate of the match\nDatetime\nUsed to align matches with weather and betting data\n\n\nHomeTeam\nName of the home team\nCategorical\nAnalyze home team performance\n\n\nAwayTeam\nName of the away team\nCategorical\nCompare with home team performance\n\n\nFTHG\nFull-time home goals\nInteger\nKey for match outcome analysis\n\n\nFTAG\nFull-time away goals\nInteger\nKey for match outcome analysis\n\n\nFTR\nFull-time result (H=Home Win, D=Draw, A=Away Win)\nCategorical\nEvaluate outcome trends and betting accuracy\n\n\nHS\nHome team shots\nInteger\nAnalyze team performance metrics\n\n\nAS\nAway team shots\nInteger\nAnalyze team performance metrics\n\n\n\nWe currently have the unprocessed, uncombined data-set as soccer22-23.csv in our raw data directory, but this will be merged to form a soccer21-23.csv dataset (a total of 760 rows).\n\nmatch_data &lt;- read.csv(here(\"data\", \"raw_data\", \"soccer21-22_with_location.csv\"))\nglimpse(match_data)\n\nRows: 380\nColumns: 23\n$ Date     &lt;chr&gt; \"13/08/2021\", \"14/08/2021\", \"14/08/2021\", \"14/08/2021\", \"14/0…\n$ HomeTeam &lt;chr&gt; \"Brentford\", \"Man United\", \"Burnley\", \"Chelsea\", \"Everton\", \"…\n$ AwayTeam &lt;chr&gt; \"Arsenal\", \"Leeds\", \"Brighton\", \"Crystal Palace\", \"Southampto…\n$ FTHG     &lt;int&gt; 2, 5, 1, 3, 3, 1, 3, 0, 2, 1, 2, 2, 0, 2, 5, 2, 1, 0, 0, 4, 5…\n$ FTAG     &lt;int&gt; 0, 1, 2, 0, 1, 0, 2, 3, 4, 0, 0, 0, 0, 2, 0, 0, 1, 1, 2, 1, 0…\n$ FTR      &lt;chr&gt; \"H\", \"H\", \"A\", \"H\", \"H\", \"H\", \"H\", \"A\", \"A\", \"H\", \"H\", \"H\", \"…\n$ HTHG     &lt;int&gt; 1, 1, 1, 2, 0, 1, 2, 0, 2, 0, 1, 1, 0, 1, 2, 2, 1, 0, 0, 1, 3…\n$ HTAG     &lt;int&gt; 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 2, 0, 0…\n$ HTR      &lt;chr&gt; \"H\", \"H\", \"H\", \"H\", \"A\", \"H\", \"H\", \"A\", \"H\", \"D\", \"H\", \"H\", \"…\n$ Referee  &lt;chr&gt; \"M Oliver\", \"P Tierney\", \"D Coote\", \"J Moss\", \"A Madley\", \"C …\n$ HS       &lt;int&gt; 8, 16, 14, 13, 14, 9, 13, 14, 17, 13, 27, 10, 7, 17, 16, 13, …\n$ AS       &lt;int&gt; 22, 10, 14, 4, 6, 17, 11, 19, 8, 18, 9, 9, 14, 17, 1, 10, 15,…\n$ HST      &lt;int&gt; 3, 8, 3, 6, 6, 5, 7, 3, 3, 3, 9, 2, 2, 4, 4, 3, 3, 6, 3, 7, 1…\n$ AST      &lt;int&gt; 4, 3, 8, 1, 3, 3, 2, 8, 9, 4, 3, 1, 3, 8, 0, 1, 4, 6, 5, 1, 0…\n$ HF       &lt;int&gt; 12, 11, 10, 15, 13, 6, 18, 4, 4, 11, 6, 8, 12, 6, 13, 11, 12,…\n$ AF       &lt;int&gt; 8, 9, 7, 11, 15, 10, 13, 14, 3, 8, 12, 18, 9, 13, 7, 6, 10, 7…\n$ HC       &lt;int&gt; 2, 5, 7, 5, 6, 5, 2, 3, 7, 3, 8, 3, 3, 8, 6, 7, 7, 5, 9, 10, …\n$ AC       &lt;int&gt; 5, 4, 6, 2, 8, 4, 4, 11, 6, 11, 4, 4, 5, 5, 1, 2, 7, 4, 8, 0,…\n$ HY       &lt;int&gt; 0, 1, 2, 0, 2, 1, 3, 1, 1, 2, 0, 3, 3, 2, 1, 4, 2, 1, 3, 0, 1…\n$ AY       &lt;int&gt; 0, 2, 1, 0, 0, 2, 1, 1, 0, 1, 0, 4, 1, 4, 0, 0, 3, 4, 0, 1, 2…\n$ HR       &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ AR       &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1…\n$ location &lt;chr&gt; \"London\", \"Manchester\", \"Burnley\", \"London\", \"Liverpool\", \"Le…\n\n\n\n\n\nAugmenting Datasets\nMatch data is planned to be supplemented with publicly sourced weather and betting odds data to form the cumulative, unprocessed raw data.\n\nWeather Data\nThis data was chosen as a potential augmentation to the match data as weather events significantly affect the playing conditions. This can influence results of the game, often in an unexpected way.\nSome teams might have strategies, or players that do well in wet conditions that slow down the overall pace of the game, and having this data in our analysis would help us test various hypothesis that can form the crux of our research questions.\n\nData Description\n\n\n\n\n\n\n\n\n\nColumn Name\nDescription\nType\nUsage in Project\n\n\n\n\ndatetime\nTimestamp of weather data\nDatetime\nAlign weather with match date\n\n\ntempmax\nMaximum temperature on match day\nFloat\nAnalyze impact of temperature on match outcomes\n\n\ntempmin\nMinimum temperature on match day\nFloat\nAnalyze impact of temperature fluctuations\n\n\nprecip\nPrecipitation (in mm)\nFloat\nEvaluate how weather impacts match performance\n\n\nwindspeed\nSpeed of wind on match day\nFloat\nAnalyze influence of wind on match results\n\n\nhumidity\nHumidity on match day\nFloat\nInvestigate correlations between humidity and match outcomes\n\n\nvisibility\nVisibility during match\nFloat\nExplore effects of low visibility on performance\n\n\n\nNote - The city-wise data will be combined/alternatively sourced to form a master weather data-set.\n\nweather_leeds &lt;- read.csv(here(\"data\", \"raw_data\", \"weather21-22\", \"Leeds.csv\"))\nglimpse(weather_leeds)\n\nRows: 268\nColumns: 33\n$ name             &lt;chr&gt; \"Leeds\", \"Leeds\", \"Leeds\", \"Leeds\", \"Leeds\", \"Leeds\",…\n$ datetime         &lt;chr&gt; \"2021-08-21\", \"2021-08-22\", \"2021-08-23\", \"2021-08-24…\n$ tempmax          &lt;dbl&gt; 17.6, 18.1, 19.6, 18.2, 19.0, 14.9, 14.2, 19.9, 15.1,…\n$ tempmin          &lt;dbl&gt; 14.9, 14.5, 13.4, 13.6, 12.8, 11.8, 10.7, 9.0, 10.9, …\n$ temp             &lt;dbl&gt; 16.1, 15.8, 15.9, 15.4, 15.2, 13.7, 12.5, 13.9, 12.9,…\n$ feelslikemax     &lt;dbl&gt; 17.6, 18.1, 19.6, 18.2, 19.0, 14.9, 14.2, 19.9, 15.1,…\n$ feelslikemin     &lt;dbl&gt; 14.9, 14.5, 13.4, 13.6, 12.8, 11.8, 10.7, 8.5, 10.9, …\n$ feelslike        &lt;dbl&gt; 16.1, 15.8, 15.9, 15.4, 15.2, 13.7, 12.5, 13.8, 12.9,…\n$ dew              &lt;dbl&gt; 14.6, 14.7, 12.8, 12.7, 12.7, 10.4, 9.5, 9.8, 10.2, 1…\n$ humidity         &lt;dbl&gt; 90.9, 93.2, 83.4, 84.5, 85.3, 80.8, 82.3, 78.1, 83.9,…\n$ precip           &lt;dbl&gt; 8.297, 6.057, 0.156, 0.000, 0.007, 0.018, 0.000, 0.00…\n$ precipprob       &lt;int&gt; 100, 100, 100, 0, 100, 100, 0, 0, 0, 100, 100, 100, 1…\n$ precipcover      &lt;dbl&gt; 41.67, 50.00, 8.33, 0.00, 4.17, 4.17, 0.00, 0.00, 0.0…\n$ preciptype       &lt;chr&gt; \"rain\", \"rain\", \"rain\", \"\", \"rain\", \"rain\", \"\", \"\", \"…\n$ snow             &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ snowdepth        &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ windgust         &lt;dbl&gt; 25.9, 24.8, 24.1, 16.2, 23.4, 35.6, 24.5, 17.3, 27.7,…\n$ windspeed        &lt;dbl&gt; 11.5, 11.8, 12.5, 9.8, 14.3, 24.3, 15.1, 8.8, 16.9, 1…\n$ winddir          &lt;dbl&gt; 174.6, 321.1, 47.1, 66.2, 35.5, 21.4, 18.0, 333.4, 17…\n$ sealevelpressure &lt;dbl&gt; 1014.6, 1019.2, 1029.7, 1032.2, 1027.9, 1024.6, 1025.…\n$ cloudcover       &lt;dbl&gt; 81.2, 81.6, 68.5, 88.5, 82.5, 91.6, 92.9, 36.3, 83.9,…\n$ visibility       &lt;dbl&gt; 24.9, 17.3, 32.4, 39.0, 25.9, 35.7, 41.4, 34.3, 30.4,…\n$ solarradiation   &lt;dbl&gt; 46.8, 149.8, 198.8, 105.6, 144.7, 123.2, 98.7, 236.4,…\n$ solarenergy      &lt;dbl&gt; 4.1, 12.9, 17.3, 9.0, 12.5, 10.8, 8.4, 20.5, 8.6, 7.8…\n$ uvindex          &lt;int&gt; 2, 8, 9, 3, 5, 3, 3, 9, 3, 4, 2, 6, 6, 2, 2, 7, 6, 7,…\n$ severerisk       &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ sunrise          &lt;chr&gt; \"2021-08-21T05:55:29\", \"2021-08-22T05:57:16\", \"2021-0…\n$ sunset           &lt;chr&gt; \"2021-08-21T20:21:54\", \"2021-08-22T20:19:38\", \"2021-0…\n$ moonphase        &lt;dbl&gt; 0.46, 0.50, 0.53, 0.56, 0.60, 0.63, 0.66, 0.69, 0.72,…\n$ conditions       &lt;chr&gt; \"Rain, Partially cloudy\", \"Rain, Partially cloudy\", \"…\n$ description      &lt;chr&gt; \"Partly cloudy throughout the day with a chance of ra…\n$ icon             &lt;chr&gt; \"rain\", \"rain\", \"rain\", \"partly-cloudy-day\", \"rain\", …\n$ stations         &lt;chr&gt; \"03346099999,F5682,F4675,03344099999,F1692,0326509999…\n\n\n\n\n\nBetting Odds Data\nThis data-set was included as part of our analysis to answer a few key questions -\n\nIs there a way to link pre-published betting odds with the outcome of league games?\nHow often are these odds pointing in the wrong direction (e.g. Underdog wins, favorite loses)\nIs there a way to quantify and link a team’s odds progression through the season to their performance\n\nFinally, we wanted to check if it is the “house” (read bookmaker) always wins? Or is there a way for a sharp (seasoned sports bettor) to outsmart the book.\n\nData Descripton\n\n\n\n\n\n\n\n\n\nColumn Name\nDescription\nType\nUsage in Project\n\n\n\n\nHomeTeam\nName of the home team\nCategorical\nCompare betting odds to actual results\n\n\nAwayTeam\nName of the away team\nCategorical\nCompare betting odds to actual results\n\n\nB365H\nBet365 odds for home team win\nFloat\nAnalyze accuracy of betting odds\n\n\nB365D\nBet365 odds for a draw\nFloat\nAnalyze odds dynamics for tied matches\n\n\nB365A\nBet365 odds for away team win\nFloat\nCompare odds with actual match outcome\n\n\nMaxH\nMaximum odds for home team win\nFloat\nTrack the highest betting odds and its correlation with results\n\n\nMaxA\nMaximum odds for away team win\nFloat\nTrack the highest betting odds and its correlation with results\n\n\n\nNote - The betting odds data from the 2 seasons (21-22, 22-23) will be combined to form a master betting odds data-set (760 rows)\n\nbet_odds &lt;- read.csv(here(\"data\", \"raw_data\", \"betting_odds21-22.csv\"))\nglimpse(bet_odds)\n\nRows: 380\nColumns: 106\n$ Div         &lt;chr&gt; \"E0\", \"E0\", \"E0\", \"E0\", \"E0\", \"E0\", \"E0\", \"E0\", \"E0\", \"E0\"…\n$ Date        &lt;chr&gt; \"13/08/2021\", \"14/08/2021\", \"14/08/2021\", \"14/08/2021\", \"1…\n$ Time        &lt;chr&gt; \"20:00\", \"12:30\", \"15:00\", \"15:00\", \"15:00\", \"15:00\", \"15:…\n$ HomeTeam    &lt;chr&gt; \"Brentford\", \"Man United\", \"Burnley\", \"Chelsea\", \"Everton\"…\n$ AwayTeam    &lt;chr&gt; \"Arsenal\", \"Leeds\", \"Brighton\", \"Crystal Palace\", \"Southam…\n$ FTHG        &lt;int&gt; 2, 5, 1, 3, 3, 1, 3, 0, 2, 1, 2, 2, 0, 2, 5, 2, 1, 0, 0, 4…\n$ FTAG        &lt;int&gt; 0, 1, 2, 0, 1, 0, 2, 3, 4, 0, 0, 0, 0, 2, 0, 0, 1, 1, 2, 1…\n$ FTR         &lt;chr&gt; \"H\", \"H\", \"A\", \"H\", \"H\", \"H\", \"H\", \"A\", \"A\", \"H\", \"H\", \"H\"…\n$ HTHG        &lt;int&gt; 1, 1, 1, 2, 0, 1, 2, 0, 2, 0, 1, 1, 0, 1, 2, 2, 1, 0, 0, 1…\n$ HTAG        &lt;int&gt; 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 2, 0…\n$ HTR         &lt;chr&gt; \"H\", \"H\", \"H\", \"H\", \"A\", \"H\", \"H\", \"A\", \"H\", \"D\", \"H\", \"H\"…\n$ Referee     &lt;chr&gt; \"M Oliver\", \"P Tierney\", \"D Coote\", \"J Moss\", \"A Madley\", …\n$ HS          &lt;int&gt; 8, 16, 14, 13, 14, 9, 13, 14, 17, 13, 27, 10, 7, 17, 16, 1…\n$ AS          &lt;int&gt; 22, 10, 14, 4, 6, 17, 11, 19, 8, 18, 9, 9, 14, 17, 1, 10, …\n$ HST         &lt;int&gt; 3, 8, 3, 6, 6, 5, 7, 3, 3, 3, 9, 2, 2, 4, 4, 3, 3, 6, 3, 7…\n$ AST         &lt;int&gt; 4, 3, 8, 1, 3, 3, 2, 8, 9, 4, 3, 1, 3, 8, 0, 1, 4, 6, 5, 1…\n$ HF          &lt;int&gt; 12, 11, 10, 15, 13, 6, 18, 4, 4, 11, 6, 8, 12, 6, 13, 11, …\n$ AF          &lt;int&gt; 8, 9, 7, 11, 15, 10, 13, 14, 3, 8, 12, 18, 9, 13, 7, 6, 10…\n$ HC          &lt;int&gt; 2, 5, 7, 5, 6, 5, 2, 3, 7, 3, 8, 3, 3, 8, 6, 7, 7, 5, 9, 1…\n$ AC          &lt;int&gt; 5, 4, 6, 2, 8, 4, 4, 11, 6, 11, 4, 4, 5, 5, 1, 2, 7, 4, 8,…\n$ HY          &lt;int&gt; 0, 1, 2, 0, 2, 1, 3, 1, 1, 2, 0, 3, 3, 2, 1, 4, 2, 1, 3, 0…\n$ AY          &lt;int&gt; 0, 2, 1, 0, 0, 2, 1, 1, 0, 1, 0, 4, 1, 4, 0, 0, 3, 4, 0, 1…\n$ HR          &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ AR          &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1…\n$ B365H       &lt;dbl&gt; 4.00, 1.53, 3.10, 1.25, 1.90, 1.66, 3.10, 9.00, 3.20, 5.50…\n$ B365D       &lt;dbl&gt; 3.40, 4.50, 3.10, 5.75, 3.50, 3.80, 3.20, 5.75, 3.50, 4.20…\n$ B365A       &lt;dbl&gt; 1.95, 5.75, 2.45, 13.00, 4.00, 5.25, 2.37, 1.30, 2.20, 1.6…\n$ BWH         &lt;dbl&gt; 4.00, 1.53, 3.20, 1.28, 1.95, 1.67, 3.25, 9.00, 3.30, 5.25…\n$ BWD         &lt;dbl&gt; 3.50, 4.50, 3.10, 5.75, 3.50, 3.90, 3.30, 6.00, 3.40, 4.25…\n$ BWA         &lt;dbl&gt; 1.95, 5.75, 2.40, 10.50, 3.90, 5.25, 2.30, 1.30, 2.20, 1.6…\n$ IWH         &lt;dbl&gt; 3.80, 1.55, 3.15, 1.25, 1.95, 1.70, 3.05, 7.75, 3.15, 5.25…\n$ IWD         &lt;dbl&gt; 3.40, 4.40, 3.05, 6.00, 3.45, 3.75, 3.25, 5.50, 3.45, 4.10…\n$ IWA         &lt;dbl&gt; 2.05, 5.75, 2.45, 13.00, 3.95, 5.25, 2.40, 1.35, 2.25, 1.6…\n$ PSH         &lt;dbl&gt; 4.05, 1.56, 3.30, 1.26, 2.01, 1.73, 3.18, 8.35, 3.21, 5.56…\n$ PSD         &lt;dbl&gt; 3.46, 4.57, 3.12, 6.24, 3.56, 3.79, 3.31, 5.86, 3.59, 4.09…\n$ PSA         &lt;dbl&gt; 2.05, 5.96, 2.51, 12.74, 4.10, 5.47, 2.47, 1.36, 2.32, 1.6…\n$ WHH         &lt;dbl&gt; 4.00, 1.52, 3.20, 1.25, 1.95, 1.70, 3.20, 9.00, 3.10, 5.50…\n$ WHD         &lt;dbl&gt; 3.40, 4.33, 3.00, 5.50, 3.40, 3.60, 3.10, 5.25, 3.40, 4.00…\n$ WHA         &lt;dbl&gt; 1.90, 5.80, 2.45, 13.00, 4.00, 5.25, 2.38, 1.32, 2.25, 1.6…\n$ VCH         &lt;dbl&gt; 4.10, 1.55, 3.13, 1.25, 1.95, 1.70, 3.10, 9.50, 3.25, 5.50…\n$ VCD         &lt;dbl&gt; 3.40, 4.40, 3.10, 5.75, 3.40, 3.70, 3.25, 5.50, 3.40, 4.00…\n$ VCA         &lt;dbl&gt; 2.00, 6.00, 2.45, 13.00, 4.10, 5.25, 2.38, 1.30, 2.25, 1.6…\n$ MaxH        &lt;dbl&gt; 4.62, 1.59, 3.33, 1.30, 2.04, 1.75, 3.30, 9.90, 3.36, 5.85…\n$ MaxD        &lt;dbl&gt; 3.72, 4.65, 3.20, 6.30, 3.66, 3.96, 3.40, 6.00, 3.61, 4.30…\n$ MaxA        &lt;dbl&gt; 2.10, 6.35, 2.60, 15.00, 4.25, 5.60, 2.50, 1.37, 2.36, 1.6…\n$ AvgH        &lt;dbl&gt; 4.02, 1.55, 3.19, 1.26, 1.97, 1.71, 3.14, 8.78, 3.20, 5.49…\n$ AvgD        &lt;dbl&gt; 3.43, 4.48, 3.09, 5.92, 3.53, 3.75, 3.26, 5.71, 3.51, 4.10…\n$ AvgA        &lt;dbl&gt; 2.02, 5.87, 2.49, 12.80, 4.04, 5.32, 2.41, 1.33, 2.26, 1.6…\n$ B365.2.5    &lt;dbl&gt; 2.10, 1.61, 2.50, 1.80, 2.00, 2.09, 2.00, 1.53, 1.99, 1.89…\n$ B365.2.5.1  &lt;dbl&gt; 1.72, 2.30, 1.53, 2.00, 1.80, 1.84, 1.80, 2.50, 1.94, 2.04…\n$ P.2.5       &lt;dbl&gt; 2.22, 1.67, 2.56, 1.80, 2.14, 2.08, 2.10, 1.56, 1.98, 1.89…\n$ P.2.5.1     &lt;dbl&gt; 1.73, 2.32, 1.56, 2.09, 1.78, 1.84, 1.83, 2.59, 1.93, 2.02…\n$ Max.2.5     &lt;dbl&gt; 2.26, 1.71, 2.56, 1.84, 2.14, 2.12, 2.10, 1.56, 2.01, 1.91…\n$ Max.2.5.1   &lt;dbl&gt; 1.83, 2.38, 1.63, 2.12, 1.85, 1.85, 1.87, 2.75, 1.96, 2.10…\n$ Avg.2.5     &lt;dbl&gt; 2.16, 1.65, 2.46, 1.79, 2.07, 2.04, 2.03, 1.52, 1.95, 1.85…\n$ Avg.2.5.1   &lt;dbl&gt; 1.73, 2.29, 1.57, 2.06, 1.79, 1.81, 1.82, 2.59, 1.90, 2.01…\n$ AHh         &lt;dbl&gt; 0.50, -1.00, 0.25, -1.50, -0.50, -0.75, 0.25, 1.50, 0.25, …\n$ B365AHH     &lt;dbl&gt; 1.86, 1.95, 1.80, 1.84, 2.00, 1.96, 1.83, 1.93, 1.94, 1.73…\n$ B365AHA     &lt;dbl&gt; 2.07, 1.98, 2.14, 2.09, 1.93, 1.97, 2.10, 2.00, 1.99, 2.08…\n$ PAHH        &lt;dbl&gt; 1.88, 1.96, 1.83, 1.79, 2.01, 1.96, 1.83, 1.91, 1.92, 1.76…\n$ PAHA        &lt;dbl&gt; 2.06, 1.96, 2.12, 2.12, 1.92, 1.96, 2.11, 2.02, 2.00, 2.19…\n$ MaxAHH      &lt;dbl&gt; 2.05, 2.00, 1.83, 1.93, 2.01, 1.97, 1.86, 2.00, 1.97, 1.86…\n$ MaxAHA      &lt;dbl&gt; 2.08, 2.01, 2.17, 2.12, 1.97, 1.99, 2.12, 2.02, 2.00, 2.19…\n$ AvgAHH      &lt;dbl&gt; 1.87, 1.93, 1.79, 1.83, 1.96, 1.94, 1.82, 1.94, 1.92, 1.79…\n$ AvgAHA      &lt;dbl&gt; 2.03, 1.96, 2.12, 2.07, 1.92, 1.95, 2.07, 1.95, 1.96, 2.11…\n$ B365CH      &lt;dbl&gt; 3.80, 1.61, 3.10, 1.30, 2.00, 1.70, 3.40, 6.50, 3.30, 6.00…\n$ B365CD      &lt;dbl&gt; 3.25, 4.20, 3.10, 5.25, 3.40, 3.75, 3.30, 4.75, 3.40, 4.10…\n$ B365CA      &lt;dbl&gt; 2.05, 5.25, 2.45, 11.00, 3.90, 5.00, 2.20, 1.44, 2.20, 1.5…\n$ BWCH        &lt;dbl&gt; 3.80, 1.62, 3.25, 1.33, 2.05, 1.72, 3.40, 6.75, 3.30, 6.00…\n$ BWCD        &lt;dbl&gt; 3.30, 4.10, 3.10, 5.00, 3.40, 3.70, 3.30, 4.75, 3.40, 4.20…\n$ BWCA        &lt;dbl&gt; 2.05, 5.25, 2.40, 10.00, 3.75, 5.00, 2.20, 1.45, 2.20, 1.5…\n$ IWCH        &lt;dbl&gt; 3.80, 1.65, 3.10, 1.30, 2.00, 1.73, 3.35, 6.50, 3.30, 5.50…\n$ IWCD        &lt;dbl&gt; 3.25, 4.20, 3.05, 5.25, 3.35, 3.70, 3.15, 5.25, 3.45, 3.95…\n$ IWCA        &lt;dbl&gt; 2.10, 4.90, 2.45, 11.00, 4.00, 4.90, 2.30, 1.43, 2.20, 1.6…\n$ PSCH        &lt;dbl&gt; 3.94, 1.67, 3.27, 1.34, 2.05, 1.76, 3.68, 7.00, 3.46, 5.97…\n$ PSCD        &lt;dbl&gt; 3.33, 4.20, 3.14, 5.40, 3.45, 3.77, 3.35, 4.90, 3.55, 4.25…\n$ PSCA        &lt;dbl&gt; 2.13, 5.40, 2.51, 11.00, 4.07, 5.22, 2.21, 1.48, 2.21, 1.6…\n$ WHCH        &lt;dbl&gt; 3.90, 1.57, 3.10, 1.30, 1.95, 1.66, 3.40, 7.50, 3.40, 5.80…\n$ WHCD        &lt;dbl&gt; 3.00, 4.20, 3.00, 5.25, 3.40, 3.80, 3.20, 5.00, 3.30, 3.80…\n$ WHCA        &lt;dbl&gt; 2.05, 5.50, 2.45, 10.00, 3.90, 5.00, 2.20, 1.38, 2.15, 1.6…\n$ VCCH        &lt;dbl&gt; 3.90, 1.65, 3.13, 1.33, 2.00, 1.73, 3.50, 7.00, 3.40, 6.00…\n$ VCCD        &lt;dbl&gt; 3.25, 4.10, 3.13, 5.00, 3.30, 3.70, 3.30, 4.80, 3.50, 4.00…\n$ VCCA        &lt;dbl&gt; 2.10, 5.25, 2.50, 11.00, 4.20, 5.25, 2.20, 1.45, 2.15, 1.6…\n$ MaxCH       &lt;dbl&gt; 4.20, 1.71, 3.35, 1.36, 2.12, 1.82, 3.73, 8.00, 3.62, 6.53…\n$ MaxCD       &lt;dbl&gt; 3.50, 4.33, 3.20, 5.50, 3.50, 4.13, 3.45, 5.50, 3.60, 4.33…\n$ MaxCA       &lt;dbl&gt; 2.18, 5.80, 2.56, 11.50, 4.20, 5.50, 2.30, 1.50, 2.27, 1.6…\n$ AvgCH       &lt;dbl&gt; 3.89, 1.64, 3.19, 1.33, 2.04, 1.74, 3.49, 6.80, 3.36, 5.88…\n$ AvgCD       &lt;dbl&gt; 3.28, 4.19, 3.10, 5.17, 3.39, 3.72, 3.30, 4.85, 3.50, 4.12…\n$ AvgCA       &lt;dbl&gt; 2.10, 5.22, 2.48, 10.58, 3.95, 5.06, 2.22, 1.46, 2.19, 1.6…\n$ B365C.2.5   &lt;dbl&gt; 2.37, 1.66, 2.30, 1.90, 2.20, 2.00, 2.10, 1.57, 1.90, 1.80…\n$ B365C.2.5.1 &lt;dbl&gt; 1.57, 2.20, 1.61, 1.90, 1.66, 1.80, 1.72, 2.37, 1.90, 2.00…\n$ PC.2.5      &lt;dbl&gt; 2.44, 1.70, 2.33, 1.93, 2.28, 2.08, 2.18, 1.57, 1.92, 1.88…\n$ PC.2.5.1    &lt;dbl&gt; 1.62, 2.27, 1.67, 1.98, 1.69, 1.82, 1.75, 2.56, 1.99, 2.03…\n$ MaxC.2.5    &lt;dbl&gt; 2.47, 1.75, 2.42, 1.96, 2.34, 2.15, 2.23, 1.61, 1.97, 2.00…\n$ MaxC.2.5.1  &lt;dbl&gt; 1.75, 2.37, 1.71, 2.07, 1.77, 1.93, 1.84, 2.60, 2.05, 2.17…\n$ AvgC.2.5    &lt;dbl&gt; 2.33, 1.67, 2.34, 1.90, 2.24, 2.06, 2.12, 1.55, 1.88, 1.85…\n$ AvgC.2.5.1  &lt;dbl&gt; 1.62, 2.25, 1.62, 1.94, 1.67, 1.79, 1.74, 2.48, 1.95, 1.99…\n$ AHCh        &lt;dbl&gt; 0.50, -1.00, 0.25, -1.50, -0.50, -0.75, 0.25, 1.25, 0.25, …\n$ B365CAHH    &lt;dbl&gt; 1.75, 2.05, 1.79, 2.05, 2.05, 2.02, 2.02, 1.85, 2.01, 1.84…\n$ B365CAHA    &lt;dbl&gt; 2.05, 1.75, 2.15, 1.75, 1.88, 1.91, 1.91, 2.08, 1.92, 2.09…\n$ PCAHH       &lt;dbl&gt; 1.81, 2.17, 1.81, 2.12, 2.05, 2.01, 2.04, 1.85, 2.02, 1.87…\n$ PCAHA       &lt;dbl&gt; 2.13, 1.77, 2.14, 1.81, 1.88, 1.92, 1.89, 2.09, 1.91, 2.06…\n$ MaxCAHH     &lt;dbl&gt; 2.05, 2.19, 1.82, 2.16, 2.08, 2.05, 2.04, 2.03, 2.12, 1.94…\n$ MaxCAHA     &lt;dbl&gt; 2.17, 1.93, 2.19, 1.93, 1.90, 1.95, 1.93, 2.10, 1.94, 2.15…\n$ AvgCAHH     &lt;dbl&gt; 1.80, 2.10, 1.79, 2.06, 2.03, 1.99, 1.99, 1.88, 2.00, 1.84…\n$ AvgCAHA     &lt;dbl&gt; 2.09, 1.79, 2.12, 1.82, 1.86, 1.89, 1.90, 2.01, 1.89, 2.05…\n\n\n\n\n\nData Source and Ethical Considerations\n\nMatch Data\n\nSource -\n\nThis data was sourced from Evan Gower via Kaggle (originally referenced from the tidytuesday list of datasets)\nThe extension (to the 22-23 season) was also sourced from the same user\n\nCollection Method -\n\nThe provenance of the cleaned match data is from the FootballData UK website.\nWe could not identify explicitly how this organization collects data, but it seems that the incoming data stream relies on live match data from gambling websites/book-makers.\n\nEthical Considerations -\n\nThe data on Kaggle is offered openly, but the copyright lies with the original authors (https://www.football-data.co.uk/)\nSince the original author provides the data publicly, we are within our rights to use this data for a non-commercial use case i.e. our project.\n\n\nWeather\n\nSource - Data for the weather during matches has been retrieved from the weather data vendor Visual Crossing.\nCollection Method - This provider compiles data by collecting raw measurements from observation stations located all across the world. Given that the locations of interest for us are all major cities in the U.K., we can be quite confident in the quality of this data.\nEthical Considerations -\n\nThe weather data was collected through legal and legitimate means by using the Visual Crossing platform, by adhering to the platform’s terms and conditions.\nSince there was a limit of 1000 record retrieval cap in a 24 hour period, the workload was divided among 6 team members.\nThe data was not manipulated at any point, thus allowing transperency and clear documentation of the process.\nThe data collected will solely be used for the intended purpose of this project.\n\n\nBetting Odds\n\nSource -\n\nThis data was sourced from FootballData UK\nCo-incidentally, this is also the primary data source for our cleaned match data\n\nCollection Method -\n\nWe could not identify explicitly how this organization collects data, but it seems that the incoming data stream relies on live match data from gambling websites/book-makers.\n\nEthical Considerations -\n\nSince the original author provides the data publicly, we are within our rights to use this data for a non-commercial use case i.e. our project. No ethical conflicts or ambiguity here."
  },
  {
    "objectID": "proposal.html#research-questions",
    "href": "proposal.html#research-questions",
    "title": "Analyzing English Premier League Match Data",
    "section": "Research Questions",
    "text": "Research Questions\n\nHow do extreme pre-match weather conditions (such as heavy rain, strong winds, or cold temperatures) influence the likelihood of surprising outcomes, such as underdog victories, and how do betting odds before the match reflect these potential surprises compared to historical odds for the same teams?\n\nRationale:\n\nWe aim to explore if extreme weather conditions lead to more unexpected outcomes, such as the underdogs (as per the pre match betting line) winning.\nIt also examines how pre-match betting odds account for these potential disruptions, by comparing them to odds for the same teams in previous matches under normal conditions.\n\nDatasets involved:\n\nMatch data\nWeather data\nPre-match betting odds.\n\n\nIs there a quantifiable home team advantage? And is this reflected in the pre-match betting odds?\n\nRationale -\n\nWe aim to trace whether there is a significant uptick in a team’s perceived performance when they are playing on their home ground\nFor similarly ranked teams, with similar records, do their betting odds reflect a perceived advantage when playing at home vs playing away?\nIf the odds are indicative of this advantage, how often does this translate to the actual result\n\nDatasets involved:\n\nMatch data\nPre-match betting odds.\n\n\nHow accurate are the pre match betting odds?\n\nRationale -\n\nWe aim to perform a simple accuracy analysis of pre match betting odds on the match outcome\nWe aim to track the sensitivity of a team’s rolling performance to the betting odds essentially tracking whether there is a recency bias built into betting odds\n\nDatasets involved:\n\nMatch data\nPre-match betting odds."
  },
  {
    "objectID": "proposal.html#analysis-plan",
    "href": "proposal.html#analysis-plan",
    "title": "Analyzing English Premier League Match Data",
    "section": "Analysis Plan",
    "text": "Analysis Plan\n\nBefore we begin the analysis, the following pre-processing steps need to be performed -\n\nExtending Match Data - We need to merge the match data from 21-22 with 22-23 seasons to give us a parent match data-set\nFlattening and Normalizing Weather Data - Our weather data is currently city-wise, we need to aggregate this into a single data-set, and create a foreign key or identifier which will help us join it with the match data\n\nAdditional statistical metrics might need to be calculated - Average Temperature, Precipitation etc.\n\nBetting Odds Data - Since none of us have experience with sports betting, we need to understand and isolate the important data points vis-a-vis bookmaking and betting odds and merge them into the match data-set.\n\nThe ETL has been completed via etl\\dataPreprocessing.qmd to extract the merged dataset that will be used as the main data source for this project - soccer_main.csv"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Analyzing English Premier League Match Data",
    "section": "",
    "text": "This project focuses on analyzing and visualizing data from the English Premier League (soccer), covering the 2021-2023 seasons. Using match data as the core data-set, the analysis incorporates additional weather and betting odds data to explore various factors that may influence game outcomes.\nWe aim to uncover patterns such as home ground advantage, the impact of weather on match results, and the relationship between pre-published betting odds and actual outcomes.\nThe project prioritizes accessibility by presenting the findings in an engaging and easy-to-understand format for a wider audience."
  },
  {
    "objectID": "index.html#abstract",
    "href": "index.html#abstract",
    "title": "Analyzing English Premier League Match Data",
    "section": "",
    "text": "This project focuses on analyzing and visualizing data from the English Premier League (soccer), covering the 2021-2023 seasons. Using match data as the core data-set, the analysis incorporates additional weather and betting odds data to explore various factors that may influence game outcomes.\nWe aim to uncover patterns such as home ground advantage, the impact of weather on match results, and the relationship between pre-published betting odds and actual outcomes.\nThe project prioritizes accessibility by presenting the findings in an engaging and easy-to-understand format for a wider audience."
  },
  {
    "objectID": "index.html#proposed-app-layout",
    "href": "index.html#proposed-app-layout",
    "title": "Analyzing English Premier League Match Data",
    "section": "Proposed App Layout",
    "text": "Proposed App Layout\n\nDescriptive Statistics\n\n\n\n\n\n\nWe aim to simply present the texture of the data with this section\n\nThe left hand panel will feature the list of teams, and the user can select 1 team to see their trend over the season, and 2, for a head-to-head comparison. When 1 team is selected, the graphical display pane will plot the dates on which the team played on the x axis, the pre-match odds on the y axis, along with a tooltip to show which team they’re playing against.\nThe dates of extreme weather, selected through extreme upper and lower percentiles, are highlighted similarly as was done in HW2 Q3. Along each plot point, the underdog or favorite is determined based on their number of wins up until that date, and color coded accordingly. When 2 teams are selected, the resulting plot will be the same, but with the dates filtered to only show matches between the 2.\n\n\n\n\nAnalysis\n\n\n\n\n\n\nIn this section, we aim to address our research questions. While we are still working on formulating the actual visualizations and analysis here, the crux of our efforts is captured in our research questions, which are detailed in the proposal."
  },
  {
    "objectID": "index.html#motivation",
    "href": "index.html#motivation",
    "title": "Analyzing English Premier League Match Data",
    "section": "Motivation",
    "text": "Motivation\n\nThe Why\n\nAll of us are avid sports fans (like most of you!)\nModern sports, especially those which have large fan-bases around the world are data-rich\nThe English Premier League is the most watched football (soccer) league in the world (Over 3 billion viewers every season)\nLarge publicly available supplementary data-sets (weather, betting odds etc.)\n\n\n\nThe What\n\nWe focus on 2 key variables in our analysis -\n\nWeather\nBetting Odds\n\nOur main motivation is to identify whether these variables can be accurate predictors of match outcomes\nWe also examine secondary relationships like -\n\n“Whether referee decisions are uniformly distributed or can bias be quantitatively established ?”"
  },
  {
    "objectID": "index.html#data-preprocessing",
    "href": "index.html#data-preprocessing",
    "title": "Analyzing English Premier League Match Data",
    "section": "Data Preprocessing",
    "text": "Data Preprocessing\n\nDefining the Data Sources\nWe started off with 3 distinct data sources as mentioned in our proposal -\n\nMatch Data\nWeather Data\nBetting Odds Data\n\nSince all these data-sets were of different dimensions and different time frames, we first had to pre-process, transform and merge these data-sets into a main data-set which would power our Shiny App.\n\n\nCollect Source Data\n\nWe began with collating all the different data-set types in one place, and the following code does that\n\n\n\nNormalizing Data\n\nThe next task was to normalize the data\nSince the dates, formats and dimensions of the data were different, we had to normalize everything to a match-level time-frame\n\n\n\nProcess Dates\n\nA key step here was to normalize the dates themselves\nThis was done by standardizing the date format\n\n\n\nAppend, Join and Merge Datasets\n\nWe then appended individual datasets of the same type to create a unified dataset that spans from 21-23\n\n\nWe sanitized the data by converting all text types to lowercase\n\n\nWe then joined -\n\nThe weather and soccer data on [date, location]\nThe combined data with betting odds on [date, HomeTeam, AwayTeam]\n\n\n\nWe then combined the match data and weather data\n\n\nThis gave us the final output - our merged main data-set"
  },
  {
    "objectID": "index.html#eda",
    "href": "index.html#eda",
    "title": "Analyzing English Premier League Match Data",
    "section": "EDA",
    "text": "EDA\n\nOne of the key challenges was to extend and merge the data-sets together into one main data source to power our Shiny App\n\n\n\nWhile the rest of the data is self explanatory, the betting odds are the only esoteric variables we have in our dataset\n\nOdds - Fractional - Represent the fractional payout - Example - 5 or 5/1 means 5 times the wagered amount would be paid out if the bet is won\n\nOur initial analysis included the following -\n\nBasic visualizations to check the spread of data\nFind a visually apparent correlation between betting odds and match outcomes\n\nWe were able to establish that in most cases (~85% of the times) - The match winner is the team with better odds\n\n\nWe then examined the link between weather data and it’s effect on match outcomes\n\nWe assume betting odds to factor in weather forecasts\nWhile the weather data does not have a normalizing effect on betting odds\n\nWe observed that an upset (team with worse odds winning) is more likely in extreme weather conditions especially rain"
  },
  {
    "objectID": "index.html#visualizations",
    "href": "index.html#visualizations",
    "title": "Analyzing English Premier League Match Data",
    "section": "Visualizations",
    "text": "Visualizations\nWe shall now discuss our observations based on the visualizations (with one example per visualization). A detailed, interactive view can be found in the Final Shiny folder which contains the Shiny App. Please run it to view the dashboard\n\nBetting Odds vs Match Outcomes\n\n\n\nChart Description\n\nOdds on the y-axis\nIndividual matches on the x-axis\nVertical red shaded strips represent extreme weather\n\nFor any given match, if the selected team is below the opponent team on the lollipop chart, it means the selected team had better pre-match odds\nThe color of the stick represents the result, a green stick represents the selected team winning that match, red represents a loss\n\nFrom the above visualization, we see that betting odds are indeed a good predictor of match outcomes, with green sticks being more common where the selected team has better odds (selected team is below the opponent)\n\nReferee Bias\n\n\n\nHere we have a simple pie chart representing the fouls and cards awarded by a referee to the home team and the away team (across all the games they refereed)\nWe did not find a large skew across decisions, thereby negating the possibility of explicit bias, but we did observe some referees were harsher to away teams overall, but that could just be the state of play - We were not able to find conclusive evidence.\n\n\nWeather Impact on Match Outcomes\n\n\n\nThis stacked bar represents the distribution of match results across a temperature range (on the x-axis)\nWe observe that we see more draws in extreme weather conditions (higher and lower)\n\nThis could be anecdotally attributed to extreme weather slowing the pace of the game down"
  },
  {
    "objectID": "index.html#conclusion-and-future-work",
    "href": "index.html#conclusion-and-future-work",
    "title": "Analyzing English Premier League Match Data",
    "section": "Conclusion and Future Work",
    "text": "Conclusion and Future Work\n\nVisual evidence of correlation between betting odds and match results has been observed\nReferee bias was not conclusively found in this analysis\nThis is not a perfectly quantitative analysis as we were more focused on visualizations\nFuture work could include a more quantitative, stats-heavy approach to answering these questions -\n\nPeform hypothesis testing\nQuantitative Modelling of the dsata\nClassification systems to predict match outcomes"
  },
  {
    "objectID": "contract.html",
    "href": "contract.html",
    "title": "Team MildCats",
    "section": "",
    "text": "Team Project Contract\n\nProject Title: Analysis and Visualization of Match Trends in Premier League (2021-2022)\nTeam Members:\n\nPrajwal Sathyanarayana (prajwals@arizona.edu)\nSankalp Sethi (sankalpsethi@arizona.edu)\nSiva Bhargav Ravula (sivabhargav@arizona.edu)\nSolman Sarva (solmansarva@arizona.edu)\nTirth Piyush Shah (tirthshah1@arizona.edu)\nVishnu Rendla (vishnurendla@arizona.edu)\nYash Salokhe (yashsalokhe@arizona.edu)\n\nProject Overview\n\nProject Goals:\n\nThis project explores Premier League match data from the 2021-2022 season, combined with additional supplementary datasets, to answer research questions about match outcomes, referee decisions, team performance, and betting odds accuracy.\nThe goal is to analyze trends in fouls, cards, home-team advantages, and betting outcomes, while investigating whether referee behavior influences match results.\n\nExpected Deliverables\n\nCleaned and merged dataset combining match and betting data\nVisualizations: Scatter plots, bar charts, heatmaps, and model output visualizations\nA final report with analysis and critiques of the methods used\nPresentation slides summarizing the project’s findings\nReproducible R code submitted through GitHub\nA quarto dashboard/shiny app (TBD)\n\nLearning Objectives:\n\nEnhance skills in data visualization and analysis of referee behavior and trends in fouls and cards\nDevelop expertise in dataset merging and data integration, exploring home team advantages and referee behavior\nAnalyze how team strategies such as possession and shots on target correlate with match outcomes and betting odds\nThis list shall be expanded as needed through the course of the project, and learning shall not be limited by each members’ role. We shall all contribute to, and learn throughout the project.\n\n\nTeam Roles and Responsibilities\n\nRoles :\n\nProject Manager: Siva Bhargav Ravula\n\nEnsures timelines are met, organizes meetings, and manages communications.\n\nData Analyst 1: Yash Salokhe\n\nJointly responsible for data cleaning, analysis, and exploratory visualizations.\n\nData Analyst 2: Sankalp Sethi\n\nJointly responsible for data cleaning, analysis, and exploratory visualizations.\n\nVisualization Specialist 1: Prajwal Sathyanarayana\n\nJointly conceptualizes and designs the final visualizations, makes aesthetic choices.\n\nVisualization Specialist 2: Solman Sarva\n\nJointly conceptualizes and designs the final visualizations, makes aesthetic choices.\n\nDocumentation Lead: Vishnu Rendla\n\nKeeps detailed notes of meetings, ensures all project decisions are documented, and handles the final report (with contributions from the team).\n\nIssue Manager: Tirth Piyush Shah\n\nThis role will help us capturing the issues/feedback from peers or other teams and addressing them.\n\n\nResponsibilities:\nGeneral Responsibilities: Each team member is responsible for:\n\nParticipating actively in all meetings.\nCompleting their assigned tasks on time.\nCommunicating openly and promptly if issues arise.\n\n\nCommunication Plan\n\nMeeting Schedule: Weekly on Fridays at 03:00 PM via Google Meet\nPrimary Communication Platform: WhatsApp Group, Slack Group\nDecision-Making Process: Decisions will be made by consensus; if a consensus cannot be reached, a vote will be taken.\n\nWork Plan and Timeline\n\nReal time project updates can be viewed here\n\nAccountability and Expectations\n\nAttendance Policy: All team members are expected to attend scheduled meetings unless previously discussed.\nQuality of Work: All deliverables should be completed to a professional standard.\nDeadlines: All members are responsible for meeting deadlines. If someone cannot meet a deadline, they must notify the team in advance.\n\nConflict Resolution Plan\n\nConflict Management: If a conflict arises, team members will:\n\nDiscuss the issue openly during a team meeting.\nAttempt to resolve the issue through compromise.\nIf the conflict persists, consult the project supervisor for guidance.\n\n\nSignatures\nBy signing below, each team member agrees to the terms of this contract and commits to working together effectively and respectfully.\n\nPrajwal Sathyanarayana Date: 09/30/2024\nSankalp Sethi Date: 09/30/2024\nSiva Bhargav Ravula Date: 09/30/2024\nSolman Sarva Date: 09/30/2024\nTirth Piyush Shah Date: 09/30/2024\nVishnu Rendla Date: 09/30/2024\nYash Salokhe Date: 09/30/2024"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This project was developed by [Mild Cats] For INFO 526 - Data Analysis and Visualization at the University of Arizona, taught by Dr. Greg Chism. The team is comprised of the following team members.\n\nTeam member 1: Siva, Final year graduate student in school of Information Science, would be primarily contributing as a Project Manager to Project - 1.\nTeam member 2: Prajwal Sathyanarayana, First year Grad student at College of Information Science,\nUniversity of Arizona, contributing as Visualization Specialist\nTeam member 3: Sankalp Sethi, Final year graduate student pursuing a Masters in Information Science - Machine Learning, contributing to Data Discovery, Processing and Analysis amongst other things\nTeam member 4: Vishnu Rendla: Second year Grad student in Information Science - Machine Learning, contributing as Documentation lead, and supporting with individual tasks.\nTeam member 5: Tirth Shah\nTeam member 6: Solman Sarva: Second year graduate student pursuing a Masters in Information Science and Machine Learning, would be contributing as Visualization Specialist.\nTeam member 7: Yash Salokhe: First year graduate student pursuing a Masters in Data Science, will primarily be contributing to Data Discovery, Processing and Analysis."
  },
  {
    "objectID": "etl/dataPreprocessing.html",
    "href": "etl/dataPreprocessing.html",
    "title": "Data Preprocessing",
    "section": "",
    "text": "#| label: Setup\n\nif (!require(\"pacman\")) \n  install.packages(\"pacman\")\n\n# use this line for installing/loading\nsuppressMessages(suppressWarnings(pacman::p_load(here,\n                                                 readr,\n                                                 lubridate,\n                                                 readxl,\n                                                 dplyr,\n                                                 writexl)))\n         \nsuppressMessages(suppressWarnings(\n  devtools::install_github(\"tidyverse/dsbox\")\n))\n\n# Setting theme for ggplot2\nggplot2::theme_set(ggplot2::theme_minimal(base_size = 14))\n\n\nNormalizing Dates\n\nCreate source file list\n\nraw_data_path &lt;- file.path(getwd(), \"..\", \"data\" , \"raw_data\")\npreproc_data_path &lt;- file.path(getwd(), \"..\", \"data\", \"preproc_data\")\n\n# Normalize the path to make sure it's in the correct format\n# here() was not resolving the absolute path, so had to use getwd()\nraw_data_path &lt;- normalizePath(raw_data_path)\npreproc_data_path &lt;- normalizePath(preproc_data_path)\n\n# Create the preprocessed directory if it doesn't exist\nif (!dir.exists(preproc_data_path)) {\n  dir.create(preproc_data_path)\n}\n\n# Get a list of all CSV and Excel files in the raw_data path\n\nfile_list &lt;- list.files(path = raw_data_path, pattern = \"\\\\.(csv|xlsx)$\", full.names = TRUE)\n\n\n\nDefine date normalization function\n\nnormalize_date &lt;- function(file) {\n  # Check the file extension and load the data accordingly\n  if (grepl(\"\\\\.csv$\", file)) {\n    data &lt;- read_csv(file)\n  } else if (grepl(\"\\\\.xlsx$\", file)) {\n    data &lt;- read_excel(file)\n  } else {\n    stop(\"Unsupported file format\")\n  }\n  \n  # Find columns containing 'date' or 'datetime' in their names\n  date_columns &lt;- names(data)[grepl(\"date|datetime\", tolower(names(data)))]\n  \n  # Convert identified date columns to YYYY-MM-DD format, checking DD-MM-YYYY first\n  if (length(date_columns) &gt; 0) {\n    data &lt;- data |&gt;\n      mutate(across(all_of(date_columns), ~ {\n        # First, try parsing with DD-MM-YYYY explicitly\n        parsed_date &lt;- as.Date(., format = \"%d-%m-%Y\")\n        \n        # For any remaining NA values, try additional formats\n        parsed_date &lt;- ifelse(\n          is.na(parsed_date),\n          as.Date(., tryFormats = c(\"%Y-%m-%d\", \"%m-%d-%Y\", \"%d/%m/%Y\", \"%m/%d/%Y\")),\n          parsed_date\n        )\n        \n        # Ensure parsed_date is reasonable (e.g., year &gt;= 1900), else return NA as Date\n        parsed_date &lt;- ifelse(!is.na(parsed_date) & year(parsed_date) &gt;= 1900, parsed_date, as.Date(NA))\n        \n        # Convert to standard YYYY-MM-DD format explicitly\n        as.Date(parsed_date, format = \"%Y-%m-%d\")\n      }))\n  } else {\n    warning(paste(\"No date column found in\", file))\n  }\n  \n  # Return the processed data\n  return(data)\n}\n\n\n\nProcess Dates\n\nfor (file in file_list) {\n  # Normalize dates in the data\n  processed_data &lt;- normalize_date(file)\n  \n  # Get the original filename\n  filename &lt;- paste0(\"date_norm_\", basename(file))\n  \n  # Define the path to save the processed file\n  save_path &lt;- file.path(preproc_data_path, filename)\n  \n  # Save the processed data\n  if (grepl(\"\\\\.csv$\", file)) {\n    write_csv(processed_data, save_path)\n  } else if (grepl(\"\\\\.xlsx$\", file)) {\n    write_xlsx(processed_data, save_path)\n  }\n}\n\n\n\nAppend, Join and Merge Datasets\n\nWe will first append individual datasets of the same type to create a unified dataset that spans from 21-23\n\n\npreproc_data_path &lt;- file.path(getwd(), \"..\", \"data\", \"preproc_data\")\npreproc_data_path &lt;- normalizePath(preproc_data_path)\n\npreproc_file_list &lt;- list.files(preproc_data_path, pattern = \"\\\\.(csv|xlsx)$\", full.names = TRUE)\n\n# Collect all CSV and Excel files in the directory\nfile_list &lt;- list.files(preproc_data_path, pattern = \"\\\\.(csv|xlsx)$\", full.names = TRUE)\n\n# Initialize an empty list to store loaded data by type\npreproc_data_list &lt;- list(betting_odds = list(), weather = list(), soccer = list())\n\n# Load each file into the appropriate list based on type\nfor (file in file_list) {\n  data &lt;- if (grepl(\"\\\\.csv$\", file)) read_csv(file) else read_excel(file)\n  \n  if (grepl(\"betting_odds\", file)) {\n    preproc_data_list$betting_odds &lt;- c(preproc_data_list$betting_odds, list(data))\n  } else if (grepl(\"merged_weather|weather_data\", file)) {\n    preproc_data_list$weather &lt;- c(preproc_data_list$weather, list(data))\n  } else if (grepl(\"soccer\", file)) {\n    preproc_data_list$soccer &lt;- c(preproc_data_list$soccer, list(data))\n  }\n}\n\nif (length(preproc_data_list$betting_odds) &gt; 0) {\n  betting_odds_combined &lt;- bind_rows(preproc_data_list$betting_odds)\n} else {\n  betting_odds_combined &lt;- data.frame() \n}\n\n\nif (length(preproc_data_list$weather) &gt; 0) {\n  weather_combined &lt;- bind_rows(preproc_data_list$weather)\n} else {\n  betting_odds_combined &lt;- data.frame()\n}\n\nif (length(preproc_data_list$soccer) &gt; 0) {\n  soccer_combined &lt;- bind_rows(preproc_data_list$soccer)\n} else {\n  soccer_combined &lt;- data.frame()\n}\n\n\nNormalize column names by converting all to lowercase\n\n\nsoccer_combined &lt;- soccer_combined |&gt; rename_with(tolower) |&gt; distinct()\nbetting_odds_combined &lt;- betting_odds_combined |&gt; rename_with(tolower) |&gt; distinct()\nweather_combined &lt;- weather_combined |&gt; rename_with(tolower) |&gt;\n  rename(location = name, date = datetime) |&gt; distinct()\n\n\nWe then join -\n\nThe weather and soccer data on [date, location]\nThe combined data with betting odds on [date, HomeTeam, AwayTeam]\n\n\n\n# Normalize in soccer_combined\nsoccer_combined &lt;- soccer_combined |&gt;\n  rename_with(tolower) |&gt;\n  mutate(location = ifelse(tolower(location) == \"newcastle upon tyne\", \"Newcastle\", location)) |&gt;\n  distinct()\n\n# Normalize in betting_odds_combined\nbetting_odds_combined &lt;- betting_odds_combined |&gt;\n  rename_with(tolower) |&gt;\n  mutate(hometeam = ifelse(tolower(hometeam) == \"newcastle upon tyne\", \"Newcastle\", hometeam),\n         awayteam = ifelse(tolower(awayteam) == \"newcastle upon tyne\", \"Newcastle\", awayteam)) |&gt;\n  distinct()\n\n# Normalize in weather_combined\nweather_combined &lt;- weather_combined |&gt;\n  rename_with(tolower) |&gt;\n  mutate(location = ifelse(tolower(location) == \"newcastle upon tyne\", \"Newcastle\", location)) |&gt;\n  distinct()\n\n\n# Ensure that date and location columns are consistent in both datasets\nsoccer_combined &lt;- soccer_combined |&gt;\n  mutate(date = as.Date(date), location = as.character(location))\n\nweather_combined &lt;- weather_combined |&gt;\n  mutate(date = as.Date(date), location = as.character(location))\n\n# Perform the left join with only matching rows on date and location\nsoccer_pre &lt;- soccer_combined |&gt;\n  left_join(weather_combined, by = c(\"date\", \"location\"))\n\nsoccer_pre &lt;- soccer_pre |&gt;\n  left_join(betting_odds_combined, by = c(\"date\", \"hometeam\", \"awayteam\"))\n\n\nfinal_data_path = file.path(getwd(), \"..\", \"data\", \"soccer_main.csv\")\n  \nfinal_data_path &lt;- normalizePath(final_data_path)  \n  \nwrite_csv(soccer_pre, final_data_path)\n\n\n# Removing duplicate columns\n\n# Identify columns with .x and .y suffixes\nduplicate_columns &lt;- unique(gsub(\"\\\\.x$|\\\\.y$\", \"\", names(soccer_pre)[grepl(\"\\\\.x$|\\\\.y$\", names(soccer_pre))]))\n\n# Condense columns by combining .x and .y versions, then removing suffixes\nfor (col in duplicate_columns) {\n  soccer_pre[[col]] &lt;- coalesce(soccer_pre[[paste0(col, \".x\")]], soccer_pre[[paste0(col, \".y\")]])\n  soccer_pre &lt;- soccer_pre %&gt;% select(-matches(paste0(\"^\", col, \"\\\\.(x|y)$\")))\n}\n\n\nfinal_data_path = file.path(getwd(), \"..\", \"data\", \"soccer_main.csv\")\n  \nfinal_data_path &lt;- normalizePath(final_data_path)  \n  \nwrite_csv(soccer_pre, final_data_path)\n\n\nThis notebook needs comments, re-organization of code - Will get it done before Milestone 3"
  },
  {
    "objectID": "presentation.html#the-why",
    "href": "presentation.html#the-why",
    "title": "Analyzing English Premier League Match Data",
    "section": "The Why",
    "text": "The Why\n\nAll of us are avid sports fans (like most of you!)\nModern sports, especially those which have large fan-bases around the world are data-rich\nThe English Premier League is the most watched football (soccer) league in the world (Over 3 billion viewers every season)\nLarge publicly available supplementary data-sets (weather, betting odds etc.)"
  },
  {
    "objectID": "presentation.html#the-what",
    "href": "presentation.html#the-what",
    "title": "Analyzing English Premier League Match Data",
    "section": "The What",
    "text": "The What\n\nWe focus on 2 key variables in our analysis -\n\nWeather\nBetting Odds\n\nOur main motivation is to identify whether these variables can be accurate predictors of match outcomes\nWe also examine secondary relationships like -\n\n“Whether referee decisions are uniformly distributed or can bias be quantitatively established ?”"
  },
  {
    "objectID": "presentation.html#overview",
    "href": "presentation.html#overview",
    "title": "Analyzing English Premier League Match Data",
    "section": "Overview",
    "text": "Overview\n\n\n\n\n\n\n\n\n\nData\nDimensions\nSource\nKey Data Points\n\n\n\n\nMatch Data\n760 x 6\nTidyTuesday Repository\nFinal Result, Home/Away Goals\n\n\nBetting Odds\n760 x 12\nFootballData UK\nBetting Odds from Various Bookmakers\n\n\nWeather\n760 x 20\nOpenweather API et al.\nTemperature, Precipitation, Humidity etc.\n\n\n\n\nAll data was sourced from publicly available, free to use APIs and archives\nThe original tidytuesday dataset contained data for the 2021-22 season only, we found the data for subsequent seasons published by the same author"
  },
  {
    "objectID": "presentation.html#setting-up-the-main-dataset",
    "href": "presentation.html#setting-up-the-main-dataset",
    "title": "Analyzing English Premier League Match Data",
    "section": "Setting Up the Main Dataset",
    "text": "Setting Up the Main Dataset\n\nOne of the key challenges was to extend and merge the datasets together into one main data source to power our Shiny App\nIt is worth going through a few basic terms and what they mean -\n\nOdds - Fractional - Represent the fractional payout - Example - 5 or 5/1 means 5 times the wagered amount would be paid out if the bet is won\nLet us take a quick look at the raw data before we proceed"
  },
  {
    "objectID": "presentation.html#expectations-vs-reality",
    "href": "presentation.html#expectations-vs-reality",
    "title": "Analyzing English Premier League Match Data",
    "section": "Expectations vs Reality",
    "text": "Expectations vs Reality\n\nGoing into this project, we had certain pre-conceived notions around the correlation between betting odds and match results\nOur intial EDA revealed results that were in line with our expectations - Pre-match odds were accurate indicators of match results\nWeather has limited, but observable impact on match outcomes - A higher probability of an upset in extreme weather"
  },
  {
    "objectID": "presentation.html#conclusion-and-future-work",
    "href": "presentation.html#conclusion-and-future-work",
    "title": "Analyzing English Premier League Match Data",
    "section": "Conclusion and Future Work",
    "text": "Conclusion and Future Work\n\nVisual evidence of correlation between betting odds and match results\nReferee bias was not conclusively found in this analysis\nThis is not a perfectly quantitative analysis as we were more focused on visualizations\n\nBut future work could include a more quantitative, stats-heavy approach to answering these questions"
  }
]