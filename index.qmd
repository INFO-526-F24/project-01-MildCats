---
title: "Analyzing English Premier League Match Data"
subtitle: "INFO 526 - Fall 2024 - Project 01"
author: 
  - name: "MildCats"
    affiliations:
      - name: "School of Information, University of Arizona"
description: "Exploring the relationship between English Premier League match outcomes and secondary variables (weather, betting odds and rolling performance records)"
format:
   html:
    code-tools: true
    code-overflow: wrap
    embed-resources: true
editor: visual
execute:
  warning: false
  echo: false
---

```{r echo=FALSE}
#| label: Setup

if (!require("pacman")) 
  install.packages("pacman")

# use this line for installing/loading
suppressMessages(suppressWarnings(pacman::p_load(here,
                                                 readr,
                                                 lubridate,
                                                 readxl,
                                                 dplyr,
                                                 writexl)))
         
suppressMessages(suppressWarnings(
  devtools::install_github("tidyverse/dsbox")
))

# Setting theme for ggplot2
ggplot2::theme_set(ggplot2::theme_minimal(base_size = 14))
```

## Abstract

This project focuses on analyzing and visualizing data from the English Premier League (soccer), covering the 2021-2023 seasons. Using match data as the core data-set, the analysis incorporates additional weather and betting odds data to explore various factors that may influence game outcomes.

We aim to uncover patterns such as home ground advantage, the impact of weather on match results, and the relationship between pre-published betting odds and actual outcomes.

The project prioritizes accessibility by presenting the findings in an engaging and easy-to-understand format for a wider audience.

## Proposed App Layout

#### Descriptive Statistics

![](images/layout-1.jpeg){fig-align="center" width="500"}

-   We aim to simply present the texture of the data with this section

    -   The left hand panel will feature the list of teams, and the user can select 1 team to see their trend over the season, and 2, for a head-to-head comparison. When 1 team is selected, the graphical display pane will plot the dates on which the team played on the x axis, the pre-match odds on the y axis, along with a tooltip to show which team they're playing against.

    -   The dates of extreme weather, selected through extreme upper and lower percentiles, are highlighted similarly as was done in HW2 Q3. Along each plot point, the underdog or favorite is determined based on their number of wins up until that date, and color coded accordingly. When 2 teams are selected, the resulting plot will be the same, but with the dates filtered to only show matches between the 2.

#### Analysis

![](images/layout-2.jpeg){fig-align="center" width="520"}

-   In this section, we aim to address our research questions. While we are still working on formulating the actual visualizations and analysis here, the crux of our efforts is captured in our research questions, which are detailed in the **proposal**.

## Motivation 

### The Why

-   All of us are avid sports fans (like most of you!)

-   Modern sports, especially those which have large fan-bases around the world are data-rich

-   The English Premier League is the most watched football (soccer) league in the world (Over 3 billion viewers every season)

-   Large publicly available supplementary data-sets (weather, betting odds etc.)

### The What

-   We focus on 2 key variables in our analysis -

    -   Weather

    -   Betting Odds

-   Our main motivation is to identify whether these variables can be accurate predictors of match outcomes

-   We also examine secondary relationships like -

    -   *"Whether referee decisions are uniformly distributed or can bias be quantitatively established ?"*

## Data Preprocessing

##### Defining the Data Sources

We started off with 3 distinct data sources as mentioned in our proposal -

-   Match Data

-   Weather Data

-   Betting Odds Data

Since all these data-sets were of different dimensions and different time frames, we first had to pre-process, transform and merge these data-sets into a main data-set which would power our Shiny App.

##### Collect Source Data

-   We began with collating all the different data-set types in one place, and the following code does that

```{r echo=FALSE}
#| label: collect-source-data

raw_data_path <- file.path(getwd(), "data" , "raw_data")
preproc_data_path <- file.path(getwd(), "data", "preproc_data")

# Normalize the path to make sure it's in the correct format
# here() was not resolving the absolute path, so had to use getwd()
raw_data_path <- normalizePath(raw_data_path)
preproc_data_path <- normalizePath(preproc_data_path)

# Create the preprocessed directory if it doesn't exist
if (!dir.exists(preproc_data_path)) {
  dir.create(preproc_data_path)
}

# Get a list of all CSV and Excel files in the raw_data path

file_list <- list.files(path = raw_data_path, pattern = "\\.(csv|xlsx)$", full.names = TRUE)
```

##### Normalizing Data

-   The next task was to normalize the data

-   Since the dates, formats and dimensions of the data were different, we had to normalize everything to a match-level time-frame

```{r echo=FALSE}
#| label: data-normalization


normalize_date <- function(file) {
  # Check the file extension and load the data accordingly
  if (grepl("\\.csv$", file)) {
    data <- read_csv(file)
  } else if (grepl("\\.xlsx$", file)) {
    data <- read_excel(file)
  } else {
    stop("Unsupported file format")
  }
  
  # Find columns containing 'date' or 'datetime' in their names
  date_columns <- names(data)[grepl("date|datetime", tolower(names(data)))]
  
  # Convert identified date columns to YYYY-MM-DD format, checking DD-MM-YYYY first
  if (length(date_columns) > 0) {
    data <- data |>
      mutate(across(all_of(date_columns), ~ {
        # First, try parsing with DD-MM-YYYY explicitly
        parsed_date <- as.Date(., format = "%d-%m-%Y")
        
        # For any remaining NA values, try additional formats
        parsed_date <- ifelse(
          is.na(parsed_date),
          as.Date(., tryFormats = c("%Y-%m-%d", "%m-%d-%Y", "%d/%m/%Y", "%m/%d/%Y")),
          parsed_date
        )
        
        # Ensure parsed_date is reasonable (e.g., year >= 1900), else return NA as Date
        parsed_date <- ifelse(!is.na(parsed_date) & year(parsed_date) >= 1900, parsed_date, as.Date(NA))
        
        # Convert to standard YYYY-MM-DD format explicitly
        as.Date(parsed_date, format = "%Y-%m-%d")
      }))
  } else {
    warning(paste("No date column found in", file))
  }
  
  # Return the processed data
  return(data)
}
```

##### Process Dates

-   A key step here was to normalize the dates themselves

-   This was done by standardizing the date format

```{r echo=FALSE}
#| label: process-dates

for (file in file_list) {
  # Normalize dates in the data
  processed_data <- normalize_date(file)
  
  # Get the original filename
  filename <- paste0("date_norm_", basename(file))
  
  # Define the path to save the processed file
  save_path <- file.path(preproc_data_path, filename)
  
  # Save the processed data
  if (grepl("\\.csv$", file)) {
    write_csv(processed_data, save_path)
  } else if (grepl("\\.xlsx$", file)) {
    write_xlsx(processed_data, save_path)
  }
}

```

##### Append, Join and Merge Datasets

-   We then appended individual datasets of the same type to create a unified dataset that spans from 21-23

```{r echo=FALSE}
#| label: append-data

preproc_data_path <- file.path(getwd(), "data", "preproc_data")
preproc_data_path <- normalizePath(preproc_data_path)

preproc_file_list <- list.files(preproc_data_path, pattern = "\\.(csv|xlsx)$", full.names = TRUE)

# Collect all CSV and Excel files in the directory
file_list <- list.files(preproc_data_path, pattern = "\\.(csv|xlsx)$", full.names = TRUE)

# Initialize an empty list to store loaded data by type
preproc_data_list <- list(betting_odds = list(), weather = list(), soccer = list())

# Load each file into the appropriate list based on type
for (file in file_list) {
  data <- if (grepl("\\.csv$", file)) read_csv(file) else read_excel(file)
  
  if (grepl("betting_odds", file)) {
    preproc_data_list$betting_odds <- c(preproc_data_list$betting_odds, list(data))
  } else if (grepl("merged_weather|weather_data", file)) {
    preproc_data_list$weather <- c(preproc_data_list$weather, list(data))
  } else if (grepl("soccer", file)) {
    preproc_data_list$soccer <- c(preproc_data_list$soccer, list(data))
  }
}

if (length(preproc_data_list$betting_odds) > 0) {
  betting_odds_combined <- bind_rows(preproc_data_list$betting_odds)
} else {
  betting_odds_combined <- data.frame() 
}


if (length(preproc_data_list$weather) > 0) {
  weather_combined <- bind_rows(preproc_data_list$weather)
} else {
  betting_odds_combined <- data.frame()
}

if (length(preproc_data_list$soccer) > 0) {
  soccer_combined <- bind_rows(preproc_data_list$soccer)
} else {
  soccer_combined <- data.frame()
}


```

-   We sanitized the data by converting all text types to lowercase

```{r echo=FALSE}
#| label: more-normalization

soccer_combined <- soccer_combined |> rename_with(tolower) |> distinct()
betting_odds_combined <- betting_odds_combined |> rename_with(tolower) |> distinct()
weather_combined <- weather_combined |> rename_with(tolower) |>
  rename(location = name, date = datetime) |> distinct()
```

-   We then joined -

    -   The weather and soccer data on \[date, location\]

    -   The combined data with betting odds on \[date, HomeTeam, AwayTeam\]

```{r echo=FALSE}
#| label: merge-data


# Normalize in soccer_combined
soccer_combined <- soccer_combined |>
  rename_with(tolower) |>
  mutate(location = ifelse(tolower(location) == "newcastle upon tyne", "Newcastle", location)) |>
  distinct()

# Normalize in betting_odds_combined
betting_odds_combined <- betting_odds_combined |>
  rename_with(tolower) |>
  mutate(hometeam = ifelse(tolower(hometeam) == "newcastle upon tyne", "Newcastle", hometeam),
         awayteam = ifelse(tolower(awayteam) == "newcastle upon tyne", "Newcastle", awayteam)) |>
  distinct()

# Normalize in weather_combined
weather_combined <- weather_combined |>
  rename_with(tolower) |>
  mutate(location = ifelse(tolower(location) == "newcastle upon tyne", "Newcastle", location)) |>
  distinct()
```

-   We then combined the match data and weather data

```{r echo=FALSE}
#| label: join-weather-and-match-data

# Ensure that date and location columns are consistent in both datasets
soccer_combined <- soccer_combined |>
  mutate(date = as.Date(date), location = as.character(location))

weather_combined <- weather_combined |>
  mutate(date = as.Date(date), location = as.character(location))

# Perform the left join with only matching rows on date and location
soccer_pre <- soccer_combined |>
  left_join(weather_combined, by = c("date", "location"))

soccer_pre <- soccer_pre |>
  left_join(betting_odds_combined, by = c("date", "hometeam", "awayteam"))
```

-   This gave us the final output - our merged main data-set

```{r echo=FALSE}
#| label: final-cleanup

# Removing duplicate columns

# Identify columns with .x and .y suffixes
duplicate_columns <- unique(gsub("\\.x$|\\.y$", "", names(soccer_pre)[grepl("\\.x$|\\.y$", names(soccer_pre))]))

# Condense columns by combining .x and .y versions, then removing suffixes
for (col in duplicate_columns) {
  soccer_pre[[col]] <- coalesce(soccer_pre[[paste0(col, ".x")]], soccer_pre[[paste0(col, ".y")]])
  soccer_pre <- soccer_pre %>% select(-matches(paste0("^", col, "\\.(x|y)$")))
}


final_data_path = file.path(getwd(), "data", "soccer_main.csv")
  
final_data_path <- normalizePath(final_data_path)  
  
write_csv(soccer_pre, final_data_path)
```

## EDA 

-   One of the key challenges was to extend and merge the data-sets together into one main data source to power our Shiny App

```{=html}
<!-- -->
```
-   While the rest of the data is self explanatory, the betting odds are the only esoteric variables we have in our dataset

    -   Odds - Fractional - Represent the fractional payout - Example - 5 or 5/1 means 5 times the wagered amount would be paid out if the bet is won

-   Our initial analysis included the following -

    -   Basic visualizations to check the spread of data

    -   Find a visually apparent correlation between betting odds and match outcomes

        -   We were able to establish that in most cases (\~85% of the times) - The match winner is the team with better odds

-   We then examined the link between weather data and it's effect on match outcomes

    -   We assume betting odds to factor in weather forecasts

    -   While the weather data does not have a normalizing effect on betting odds

        -   We observed that an upset (team with worse odds winning) is more likely in extreme weather conditions especially rain

## Visualizations 

We shall now discuss our observations based on the visualizations (with one example per visualization). A detailed, interactive view can be found in the Final Shiny folder which contains the Shiny App. Please run it to view the dashboard

1.  **Betting Odds vs Match Outcomes**

    -   ![](images/clipboard-489080523.png)
        -   Chart Description
            -   Odds on the y-axis
            -   Individual matches on the x-axis
            -   Vertical red shaded strips represent extreme weather
        -   For any given match, if the selected team is below the opponent team on the lollipop chart, it means the selected team had better pre-match odds
        -   The color of the stick represents the result, a green stick represents the selected team winning that match, red represents a loss
    -   From the above visualization, we see that betting odds are indeed a good predictor of match outcomes, with green sticks being more common where the selected team has better odds (selected team is below the opponent)

2.  **Referee Bias**

    -   ![](images/clipboard-3549485583.png){width="418"}
        -   Here we have a simple pie chart representing the fouls and cards awarded by a referee to the home team and the away team (across all the games they refereed)

        -   We did not find a large skew across decisions, thereby negating the possibility of explicit bias, but we did observe some referees were harsher to away teams overall, but that could just be the state of play - We were not able to find conclusive evidence.

3.  **Weather Impact on Match Outcomes**

    -   ![](images/clipboard-3275463866.png)
        -   This stacked bar represents the distribution of match results across a temperature range (on the x-axis)
        -   We observe that we see more draws in extreme weather conditions (higher and lower)
            -   This could be anecdotally attributed to extreme weather slowing the pace of the game down

## Conclusion and Future Work

-   Visual evidence of correlation between betting odds and match results has been observed

-   Referee bias was not conclusively found in this analysis

-   This is not a perfectly quantitative analysis as we were more focused on visualizations

-   Future work could include a more quantitative, stats-heavy approach to answering these questions -

    -   Peform hypothesis testing

    -   Quantitative Modelling of the dsata

    -   Classification systems to predict match outcomes
